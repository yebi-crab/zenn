---
title: "article"
emoji: "🦁"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

## 混合精度の利用
混合精度とは、16bitと32bit浮動小数点型の両方をモデルに使ってモデルのトレーニングを高速化し、使用するメモリを少なくする手法です。
※IEEE 浮動小数点演算規格では、「単精度」＝32bit、「倍精度」＝64bit、「半精度」＝16bit をさします。

混合精度を利用することで、少ないリソースの中で学習を可能にします。



https://ja.wikipedia.org/wiki/%E5%8D%98%E7%B2%BE%E5%BA%A6%E6%B5%AE%E5%8B%95%E5%B0%8F%E6%95%B0%E7%82%B9%E6%95%B0

https://www.tensorflow.org/guide/mixed_precision?hl=ja

# 混合精度の利用
混合精度とは、16bitと32bit浮動小数点型の両方をモデルに使ってモデルのトレーニングを高速化し、使用するメモリを少なくする手法です。

※[IEEE 浮動小数点演算規格](https://ja.wikipedia.org/wiki/IEEE_754)において、以下をさします。
- 単精度 : 32bit
- 倍精度 : 64bit
- 半精度 : 16bit 

＜参考＞
https://www.tensorflow.org/guide/mixed_precision?hl=ja

# PEFTの利用
大規模な事前学習済みモデルの調整にはかなりのコストがかかりますが、PEFT（Parameter-Efficient Fine-Tuning）手法では、モデルの全パラメータではなく、少数のモデルパラメータを微調整することにより、コストが大幅に削減されます。

＜参考＞
https://github.com/huggingface/peft