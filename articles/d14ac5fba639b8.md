---
title: "ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¡ãƒ¢ã€‘æ··åˆç²¾åº¦ã®åˆ©ç”¨"
emoji: "ğŸ¥£"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["Python","æ©Ÿæ¢°å­¦ç¿’"]
published: true
---

## æ··åˆç²¾åº¦ã¨ã¯
æ··åˆç²¾åº¦ã¨ã¯ã€16bitã¨32bitæµ®å‹•å°æ•°ç‚¹å‹ã®ä¸¡æ–¹ã‚’ãƒ¢ãƒ‡ãƒ«ã«ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é«˜é€ŸåŒ–ã—ã€ä½¿ç”¨ã™ã‚‹ãƒ¡ãƒ¢ãƒªã‚’å°‘ãªãã™ã‚‹æ‰‹æ³•ã€‚
æ··åˆç²¾åº¦ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€å°‘ãªã„ãƒªã‚½ãƒ¼ã‚¹ã®ä¸­ã§å­¦ç¿’ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚

[IEEE æµ®å‹•å°æ•°ç‚¹æ¼”ç®—è¦æ ¼](https://ja.wikipedia.org/wiki/IEEE_754)ã«ãŠã„ã¦ã€ä»¥ä¸‹ã‚’ã•ã™ã€‚
- å˜ç²¾åº¦ : 32bit
- å€ç²¾åº¦ : 64bit
- åŠç²¾åº¦ : 16bit 
â€»æµ®å‹•å°æ•°ç‚¹æ¼”ç®—ï¼å®Ÿæ•°ã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§å‡¦ç†ï¼ˆæ¼”ç®—ã‚„è¨˜æ†¶ã€é€šä¿¡ï¼‰ã™ã‚‹ãŸã‚ã«æœ‰é™æ¡ã®å°æ•°ã§è¿‘ä¼¼å€¤ã¨ã—ã¦æ‰±ã†æ–¹å¼

ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯ä»¥ä¸‹ã®è¨˜äº‹ã®å›³ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã€‚
https://qiita.com/MotonobuHommi/items/f12a500d6c475ce59790#3-mixed-precision

## TensorFlowã®æ··åˆç²¾åº¦ã®ã‚¬ã‚¤ãƒ‰ã‚’å‹•ã‹ã—ã¦ã¿ã‚‹
[TensorFlowãŒæä¾›ã™ã‚‹ã‚¬ã‚¤ãƒ‰](https://www.tensorflow.org/guide/mixed_precision?hl=ja)ã‚’å‚è€ƒã«ã€Kerasã‚’åˆ©ç”¨ã—ã¦æ··åˆç²¾åº¦ã‚’ç”¨ã„ãŸå­¦ç¿’ã‚’è¡Œã£ã¦ã¿ã‚‹ã€‚


### ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
```py
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import mixed_precision

# æ··åˆç²¾åº¦ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®dtypeãƒãƒªã‚·ãƒ¼ã‚’è¨­å®š
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy) 

# inputã®æŒ‡å®š
# GPUåˆ©ç”¨æ™‚ã€æ··åˆç²¾åº¦ã«ã‚ˆã‚‹ãƒ¡ãƒªãƒƒãƒˆã‚’ç¢ºèªã§ãã‚‹ã‚ˆã†4096ãƒ¦ãƒ‹ãƒƒãƒˆã®Denseãƒ¬ã‚¤ãƒ¤ã‚’å½¢æˆ
inputs = keras.Input(shape=(784,), name='digits')
num_units = 4096

dense1 = layers.Dense(num_units, activation='relu', name='dense_1')
x = dense1(inputs)
dense2 = layers.Dense(num_units, activation='relu', name='dense_2')
x = dense2(x)

# outputã®æŒ‡å®š
# outputã¯32bitã§å‡ºåŠ›ã™ã‚‹
x = layers.Dense(10, name='dense_logits')(x)
outputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)

# ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
model = keras.Model(inputs=inputs, outputs=outputs)
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.RMSprop(),
              metrics=['accuracy'])
```
â€»Denseãƒ¬ã‚¤ãƒ¤ã§ã¯å…¨çµåˆå±¤ã‚’å½¢æˆã—ã€ã“ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å…¥åŠ›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã™ã¹ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆãŒæ¬¡ã®å±¤ã®ã™ã¹ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆã¨çµåˆã•ã‚Œã‚‹ã€‚
Denseå±¤ã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã€‚
https://qiita.com/Ishotihadus/items/c2f864c0cde3d17b7efb#%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%82%92%E4%BD%9C%E3%82%8B
https://zenn.dev/mi_ztyanya/books/9bcdf19bb90504/viewer/f19568

### å­¦ç¿’
MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã¦å­¦ç¿’ã‚’è¡Œã†ã€‚
```py
# MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ã¦å­¦ç¿’ã™ã‚‹
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = x_train.reshape(60000, 784).astype('float32') / 255
x_test = x_test.reshape(10000, 784).astype('float32') / 255
initial_weights = model.get_weights()

history = model.fit(x_train, y_train,
                    batch_size=8192,
                    epochs=5,
                    validation_split=0.2)
test_scores = model.evaluate(x_test, y_test, verbose=2)
print('Test loss:', test_scores[0])
print('Test accuracy:', test_scores[1])
```
ä»¥ä¸‹ã®å®Ÿè¡ŒçµæœãŒå¾—ã‚‰ã‚ŒãŸã€‚
```
Epoch 1/5
6/6 [==============================] - 3s 126ms/step - loss: 2.3732 - accuracy: 0.4058 - val_loss: 0.7861 - val_accuracy: 0.7893
Epoch 2/5
6/6 [==============================] - 0s 66ms/step - loss: 1.0039 - accuracy: 0.7030 - val_loss: 0.4294 - val_accuracy: 0.8905
Epoch 3/5
6/6 [==============================] - 0s 67ms/step - loss: 0.5551 - accuracy: 0.8302 - val_loss: 0.5790 - val_accuracy: 0.8098
Epoch 4/5
6/6 [==============================] - 0s 64ms/step - loss: 0.4478 - accuracy: 0.8620 - val_loss: 0.2923 - val_accuracy: 0.9076
Epoch 5/5
6/6 [==============================] - 0s 62ms/step - loss: 0.3981 - accuracy: 0.8697 - val_loss: 0.3019 - val_accuracy: 0.9081
313/313 - 1s - loss: 0.3142 - accuracy: 0.9020 - 666ms/epoch - 2ms/step
Test loss: 0.3141573965549469
Test accuracy: 0.9020000100135803
```
ã€Œ126ms/stepã€ã®éƒ¨åˆ†ãŒå„ã‚¹ãƒ†ãƒƒãƒ—ã®æ‰€è¦æ™‚é–“ã‚’ç¤ºã™ã€‚
ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å®Ÿè¡Œæ™‚é–“ã«ã¤ã„ã¦ã€æ··åˆç²¾åº¦ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–ã§ãã‚‹ã€‚

æ··åˆç²¾åº¦ã®åˆ©ç”¨ãªã—ã®å ´åˆã¯ã“ã®ãã‚‰ã„ã€‚
```
Epoch 1/5
6/6 [==============================] - 4s 289ms/step - loss: 2.4416 - accuracy: 0.3534 - val_loss: 0.8367 - val_accuracy: 0.7702
Epoch 2/5
6/6 [==============================] - 1s 236ms/step - loss: 0.8884 - accuracy: 0.7355 - val_loss: 0.4825 - val_accuracy: 0.8613
Epoch 3/5
6/6 [==============================] - 1s 242ms/step - loss: 0.5855 - accuracy: 0.8029 - val_loss: 0.5534 - val_accuracy: 0.8153
Epoch 4/5
6/6 [==============================] - 1s 239ms/step - loss: 0.4164 - accuracy: 0.8741 - val_loss: 0.4726 - val_accuracy: 0.8491
Epoch 5/5
6/6 [==============================] - 1s 240ms/step - loss: 0.3455 - accuracy: 0.8935 - val_loss: 0.2465 - val_accuracy: 0.9298
313/313 - 1s - loss: 0.2530 - accuracy: 0.9247 - 624ms/epoch - 2ms/step
Test loss: 0.252986341714859
Test accuracy: 0.9247000217437744
```


